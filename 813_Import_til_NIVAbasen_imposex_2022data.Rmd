---
  title: "74_Import_til_NIVAbasen_imposex_2020data"
author: "DHJ"
date: "2 9 2019"
output: 
  html_document:
  keep_md: true
---
  
  Make tables for inserting into NIVAbase   

For imposex (and intersex) in snails (Nucella + Littorina)  

Also adding Intersex (was added to METHODS for 2020 data)   


## 0. Setup

### a. Libraries and functions
```{r}

library(dplyr)
library(purrr)
library(lubridate)
library(stringr)
# library(ggplot2)
library(niRvana)

# If needed
# remotes::install_github("https://github.com/moodymudskipper/safejoin")
library(safejoin) # https://github.com/moodymudskipper/safejoin

source("810_Import_til_NIVAbasen_functions.R")

# "Restart" for lazy people that don't want to write the 
#    database password again (deletes all objects except database password/username)
if (FALSE){
  obj <- ls()
  obj <- obj[!obj %in% c("db_privkey", "db_pubkey", "db_pwd", "db_username")]
  rm(list = obj)
  rm(obj)
}

```

### b. Creds for connectng to Nivabasen    
Store your username and password to R (only once per R session)  
- Not needed if username and password are stored on the comuter (using keyring package)
```{r}

# set_credentials()

# Check these codes (press F2) for reminder about what comes from which tables:
# niRvana::get_biota_chemistry
# niRvana::get_samples_from_sampleid

```



## 1. Read data

### a. Year
```{r}

selected_year <- 2021

```


### b. Data to insert in NIVAbase   
1. Eider duck data are from specimens/samples NOT in the NIVAbase  
2. NILU cod data are from specimens that ARE in the NIVAbase, 
but new samples (liver) are numbered corresponding to the muscle samples
3. Biological effects in cod - existing specimens, new samples
4. VDSI (imposex) in snails - existing 'individuals' (pooled samples) and samples

```{r, message=FALSE}

folder_vdsi <- "K:/Prosjekter/Sjøvann/JAMP/2021/opparbeiding/Snegl"
folder_vdsi <- "Input_files_2021/Snegl"

#
# 1. Imposex in Littorina
#

fn <- dir(folder_vdsi, pattern = ".xlsx")
fn <- fn[!grepl("imposex_mal", fn)]
fn <- fn[!grepl("intersex", fn)]          # skip intersex for now
fn <- fn[!grepl("~", fn, fixed = TRUE)]

# Names = Extract all characters to the left of the first underscore  
names(fn) <- stringr::str_extract(fn, "[^_]+")
# names(fn)[names(fn) == "131"] <- "131G"
# fn


read_excel_snail <- function(fn){
  df <- readxl::read_excel(paste0(folder_vdsi, "/", fn), skip = 6)
  df <- df[1:6]
  df <- df[!is.na(df$`Analysert av`),]
  df
}

dat_vdsi_list <- fn %>% map(read_excel_snail)

# read_excel_snail_s <- safely(read_excel_snail)
# dat_vdsi_list <- fn %>% map(read_excel_snail_s)



# Check number of rows - should be 50
#  unless oherwise noted in sheet (15G "Fant ikke flere snegl i år, men det er over 15 hunner.")
dat_vdsi_list %>% map_int(nrow)

# Check 15G
# dat_vdsi_list[["15G"]] %>% View()
# dat_vdsi_list[["36G"]] %>% View()
# dat_vdsi_list[["15G"]] <- dat_vdsi_list[["15G"]][1:50,]  # delete last line

# Pick only number, sex and Imposex 
# ...we will deal with length and penis length later  
dat_vdsi <- dat_vdsi_list %>% 
  map(~.[c(1,3,5)]) %>%
  bind_rows(.id = "STATION_CODE") %>%
  rename(VALUE_WW = VDSI, 
         Sex = `Kj<U+00F8>nn`) %>%
  mutate(PARAM = "VDSI",
         UNIT = "idx",
         LATIN_NAME = "Nucella lapillus",
         Sex = tolower(Sex))

# View(dat_vdsi)

cat("\n------------------------------------------\n")
cat("Imposex data: \n------------------------------------------\n")
xtabs(~is.na(VALUE_WW) + addNA(Sex), dat_vdsi)


#
# 2. Intersex
#
# dir(folder_vdsi)
fn <- "71G_fugloy_intersex_LITTORINA_2021.xlsx"
df <- readxl::read_excel(paste0(folder_vdsi, "/", fn), range = "A3:G53")

dat_intersex <- df %>%
  filter(F == 1) %>%
  mutate(STATION_CODE = "71G", 
         Sex = "f",
         PARAM = "Intersex",
         UNIT = "PERCENT",
         LATIN_NAME = "Littorina littorea") %>%
  mutate(VALUE_WW = `ISI   (intersex-stadie)`*100) %>%
  select(STATION_CODE, Sex, VALUE_WW, PARAM, LATIN_NAME)

#
# 3. Combine and summarize   
#

dat <- bind_rows(dat_vdsi, dat_intersex) %>%
  filter(Sex == "f") %>%
  group_by(STATION_CODE, PARAM, LATIN_NAME) %>%
  summarise(VALUE = mean(VALUE_WW), .groups = "drop")

dat$MYEAR <- selected_year
dat$TISSUE_NAME <- "Whole soft body"

cat("\n------------------------------------------\n")
cat("Combined data: \n------------------------------------------\n")
xtabs(~PARAM, dat )

# For 2019 data:
# dat_2019 <- readRDS(file = "../Milkys/Input_data_2019/101_data_updated_2020-08-05.rds") %>%
#   filter(MYEAR == selected_year & PARAM %in% "VDSI" & !is.na(VALUE_WW)) %>%
#   group_by(MYEAR, STATION_CODE, LATIN_NAME, TISSUE_NAME, PARAM) %>%
#   summarise(VALUE = median(VALUE_WW)) %>%
#   mutate(STATION_CODE = case_when(
#     STATION_CODE == "227G" ~ "227G2",
#     TRUE ~ STATION_CODE)
#     )


```

### c1. Get samples in Labware file     
```{r}

#
# For data the same year    
#

project_name <- "O 210200.ANAIN"

# March-December data
sql <- paste(
  "select * from NIVADATABASE.LABWARE_CHECK_SAMPLE", 
  "where extract(YEAR from SAMPLED_DATE) =", selected_year, 
  "and extract(MONTH from SAMPLED_DATE) >= 3", 
  "and PROSJEKT =",
  sQuote(project_name), ";")
# sql
df_labware_01 <- get_nivabase_data(sql)

# January-February next year data
sql <- paste(
  "select * from NIVADATABASE.LABWARE_CHECK_SAMPLE", 
  "where extract(YEAR from SAMPLED_DATE) =", selected_year + 1, 
  "and extract(MONTH from SAMPLED_DATE) <= 2", 
  "and PROSJEKT =",
  sQuote(project_name), ";")
df_labware_02 <- get_nivabase_data(sql)

df_samples <- bind_rows(df_labware_01, df_labware_02) %>%
  filter(AQUAMONITOR_CODE %in% dat$STATION_CODE)

```

### c2. Check that we have all stations  

```{r}

a <- dat$STATION_CODE
b <- df_samples$AQUAMONITOR_CODE
check <- a[!a %in% b]  

if (length(check) == 0){
  message("'df_samples' contains all stations we need")
} else {
  stop("'df_samples' does NOT contain all stations we need!")
}

```

#### 227G is lacking  
```{r}

sql <- paste(
  "select * from NIVADATABASE.LABWARE_CHECK_SAMPLE", 
  "where extract(YEAR from SAMPLED_DATE) >", 2010, 
  "and AQUAMONITOR_CODE = '227G2';")
check <- get_nivabase_data(sql)

```

### d. Add dates to data    
```{r}

check <- df_samples %>%
  add_count(AQUAMONITOR_CODE) %>%
  filter(n > 1)

if (nrow(check) > 0){
  stop("'df_samples' have > 1 lines per station. Check 'check'")
}

# In this case, two records of 71G, both with same date
# Delete the "extra" one
nrow(df_samples)
df_samples <- df_samples %>%
  filter(!grepl("Snegl - Ekstra", DESCRIPTION))
nrow(df_samples)

# Merge
dat <- dat %>%
  safe_left_join(df_samples, 
                 na_matches = "never",
                 by = c("STATION_CODE" = "AQUAMONITOR_CODE"),
                 check = "BCMV") %>%
  rename(SAMPLE_DATE = SAMPLED_DATE)

```

#### Add date manually for 227G  
```{r}

sel <- dat$STATION_CODE == "227G"
sum(sel)

dat$SAMPLE_DATE[sel] <- ymd_hms("2021-11-05 00:00:00")

dat %>%
  count(STATION_CODE, SAMPLE_DATE)

```


## 2.Connection to NIVAbasen  

### Get some generic lookup tables  
```{r}

df_tissue <- get_nivabase_data(
  "select TISSUE_ID,TISSUE_NAME from NIVADATABASE.BIOTA_TISSUE_TYPES")

# TABLE DELETED
# - no longer an option to use SPECIES_ID in BIOTA_SAMPLES 
# - use TAXONOMY_CODE_ID in BIOTA_SINGLE_SPECIMENS instead -> table TAXONOMY_CODES -> table TAXONOMY 
# df_species <- get_nivabase_data(
#   "select * from NIVADATABASE.SPECIES")

# Get a list of projects
df_projects <- get_projects()   # we call it 'df_projects' (the default name)

# Get a list of stations
df_stations <- get_stations_from_project("CEMP_Biota", ignore.case = FALSE)

```


## 3. Check parameter   

### Check in METHOD_DEFINITIONS  
Mostly used: VDSI (METHOD_ID = 15631)  
- exception: 2015 used VDSI with METHOD_ID = 28589  
- has been submitted on an individual basis up to 2009, then as average values in 2015 and 2018    
- Intersex does not exist
```{r}

pars <- c("Imposex", "VDSI", "Intersex")

# Check
df_methods_test <- get_nivabase_selection("*", 
                                          "METHOD_DEFINITIONS",
                                          "NAME", 
                                          pars, 
                                          values_are_text = TRUE)
df_methods_test

# Tabulate species, years and methods
par <- "VDSI"
df_param <- df_methods_test[grepl(par, df_methods_test$NAME),]
df1 <- get_nivabase_selection("*", "BIOTA_CHEMISTRY_VALUES", "METHOD_ID", df_param$METHOD_ID)
nrow(df1)
df2 <- get_nivabase_selection("*", "BIOTA_SAMPLES", "SAMPLE_ID", df1$SAMPLE_ID) %>%
  left_join(df1 %>% select(SAMPLE_ID, METHOD_ID))  %>%
  left_join(df_methods_test %>% select(METHOD_ID, NAME, UNIT, METHOD_REF, MATRIX))  %>%
  # left_join(df_species) %>%
  left_join(df_tissue) %>%
  mutate(Year = year(SAMPLE_DATE))

xtabs(~TISSUE_NAME, df2)   # "Hel organisme"
# xtabs(~LATIN_NAME, df2)
df2 %>% 
  count(Year, NAME, UNIT, METHOD_ID, MATRIX)  # 15361

# Pick methods
df_methods <- df_methods_test %>%
  filter(METHOD_ID %in% c(15631, 35415))   # 35415 = Intersex

df_methods

# Pick parameters for later
pars <- df_methods$NAME

```
### b. Add Intersex method  
```{r}

# done last year. METHOD_ID = 35415

```

## 4. Check existing data, former years  
THIS WHOLE THING CAN BE SKIPPED (I think)
Starting from VDSI, via samples  

## 6. Check TBT data for the selected year    

### Get chemical data  
```{r}

df2_specimens_allyrs <- get_specimens_from_stationdata(
  df_stations %>% filter(STATION_CODE %in% dat$STATION_CODE))

# Get data frame of chemical results (30 seconds or so)
df_snailchem <- get_biota_chemistry(
  years = selected_year, 
  specimendata = df2_specimens_allyrs, 
  stationdata = df_stations,
  report_samples = TRUE)

cat("\nDownloaded", nrow(df_snailchem), "records\n")

# Show top of table  
xtabs(~NAME + STATION_CODE, df_snailchem)[1:8,]

```

### Get SAMPLE_ID used  
```{r}

station_sampleid <- df_snailchem %>%
  count(SAMPLE_ID, STATION_CODE)
station_sampleid

```


## 14. BIOTA_CHEMISTRY_VALUES

### a. Read data, if necessary  
Add METHOD_ID and FLAG1  
```{r}

xtabs(~PARAM, dat)

dat_summ <- dat %>%
  filter(PARAM %in% c("VDSI", "Intersex")) %>%
  mutate(
    FLAG1 = as.character(NA)
  ) %>%
  left_join(
    df_methods %>% select(NAME, METHOD_ID),
    by = c("PARAM" = "NAME")
  )

xtabs(~addNA(METHOD_ID), dat_summ)

```

### b. Add SAMPLE_ID  
Which is all we need (see code for 'make_sql_chemistry_values' in '71...functions')
```{r}

cn1 <- dat_summ %>% colnames()

n1 <- nrow(dat_summ)

# Add SAMPLE_ID to chemistry_values data
if (!("SAMPLE_ID" %in% cn1)){    # checks that SAMPLE_ID has not already been added
  dat_summ <- dat_summ %>%
    left_join(station_sampleid,
              by = "STATION_CODE",
              na_matches = "never")
}

n2 <- nrow(dat_summ)

if (n2 > n1){
  stop("Right-hand table not unique!")
} else {
  message("Left join ok, using unique values")
}



# dat_summ <- dat_summ %>%
#   safe_left_join(station_sampleid,
#                  by = "STATION_CODE",
#                  na_matches = "never",
#                  check = "MV")
# 
```
#### Check species
```{r}

if (FALSE){
  
  sp1 <- get_nivabase_selection(
    "TAXONOMY_CODE_ID, NIVA_TAXON_ID",
    "TAXONOMY_CODES",
    "TAXONOMY_CODE_ID", c(8860, 8879))
  sp2 <- get_nivabase_selection(
    "LATIN_NAME, NIVA_TAXON_ID",
    "TAXONOMY",
    "NIVA_TAXON_ID", sp1$NIVA_TAXON_ID)
  full_join(sp1, sp2)
  # TAXONOMY_CODE_ID NIVA_TAXON_ID
  # 8860	           35159	       Nucella lapillus		
  # 8879	           35017	       Littorina littorea
  
  test1 <- get_nivabase_selection(
    "SAMPLE_ID, SPECIMEN_ID",
    "BIOTA_SAMPLES_SPECIMENS",
    "SAMPLE_ID",
    station_sampleid$SAMPLE_ID)
  
  test2 <- get_nivabase_selection(
    "SPECIMEN_ID, STATION_ID, DATE_CAUGHT, SPECIMEN_NO, TAXONOMY_CODE_ID",
    "BIOTA_SINGLE_SPECIMENS",
    "SPECIMEN_ID",
    test1$SPECIMEN_ID)
  
}





```

#### Add specimen and sample for 227G (Nucella lapillus)   

```{r}

# Check data from previous year to get station ID + tissue_id
df_prev <- readRDS("Files_to_Jupyterhub_2020/01_df_2020_notstandard_2022-01-05.rds")

#
# 1. SPECIMEN
#


single_specimens_227G <- data.frame(
  STATION_ID = 50467, 
  DATE_CAUGHT = dat %>% filter(STATION_CODE == "227G") %>% pull(SAMPLE_DATE),
  TAXONOMY_CODE_ID = 8860,
  SPECIMEN_NO = 1)

make_sql_single_specimen(1, single_specimens_227G)

# USE SQL DEVELOPER TO INSERT SPECIMEN  

# Get inserted ID
sql <- paste(
  "select * from NIVADATABASE.BIOTA_SINGLE_SPECIMENS where entered_by = 'DHJ'",
  "and ENTERED_DATE > to_date('01-08-2022', 'DD-MM-YYYY');")
df_inserted <- get_nivabase_data(sql)

df_inserted$SPECIMEN_ID
# 333406

#
# 2. SAMPLE
#
sample_227G <- data.frame(
  STATION_ID = 50467, 
  TISSUE_ID = 3,
  REPNO = 1,
  TAXONOMY_CODE_ID = 8860,
  SAMPLE_DATE = dat %>% filter(STATION_CODE == "227G") %>% pull(SAMPLE_DATE),
  SAMPLE_NO = 1)

make_sql_sample(1, sample_227G)

# USE SQL DEVELOPER TO INSERT SPECIMEN  

# Get inserted ID
sql <- paste(
  "select * from NIVADATABASE.BIOTA_SAMPLES where entered_by = 'DHJ'",
  "and ENTERED_DATE > to_date('01-08-2022', 'DD-MM-YYYY');")
df_inserted <- get_nivabase_data(sql)

df_inserted$SAMPLE_ID[1]
# 247803


#
# 3. BIOTA_SAMPLES_SPECIMENS
#

sample_specimens_227G <- data.frame(
  SPECIMEN_ID = 333406,
  SAMPLE_ID = 247803)

make_sql_samples_specimens(1, sample_specimens_227G)

# USE SQL DEVELOPER TO INSERT SPECIMEN  


```


#### Add SAMPLE_ID for 227G2  
```{r}

sel <- dat_summ$STATION_CODE == "227G"

if (sum(sel) == 1){
  dat_summ$SAMPLE_ID[sel] <- 247803
}


```


#### Check
```{r}

if (sum(is.na(dat_summ$SAMPLE_ID)) > 0){
  stop("Some SAMPLE_ID lacking!")
} else {
  message("No SAMPLE_ID lacking")
}

```

### c. Make SQLs  
PASTE INTO SQL DEVELOPER TO ADD THE RECORDS   
Note to DHJ: use "SQL developer (latest version)" from desktop. Don't use the start menu.  
- remember `commit;` after running the insert sentences   
- See 'Milkys_2020_Intersex_Biota_chemistry_values.sql' in folder 'SQL_scripts'
```{r}
# make_sql_chemistry_values(1, data = dat_summ)

sql_list <- 1:nrow(dat_summ) %>% 
  map_chr(make_sql_chemistry_values, data = dat_summ)

i <- 1:length(sql_list)
sql <- paste(sql_list[i], collapse = ";\n")
sql <- paste0(sql, ";\n")
writeLines(sql, "clipboard-1024")   # copies SQLs to clipboard - go to SQL Developer and paste
                                    # "clipboard-1024" instead of "clipboard": increases available
                                    #    for the clipboard

cat("Number of SQLs: \n")
length(sql_list)  # 144

cat("\nSample of SQLs: \n")
sql_list[1:3]


```

#### Check insetrted data
```{r}

# Get inserted ID
sql <- paste(
  "select * from NIVADATABASE.BIOTA_CHEMISTRY_VALUES where entered_by = 'DHJ'",
  "and ENTERED_DATE >= to_date('01-09-2022', 'DD-MM-YYYY');")
df_inserted <- get_nivabase_data(sql)

```


## 15. Reread data  
- For checking
```{r}

# Get data frame of chemical results (30 seconds or so)
df_snailchem <- get_biota_chemistry(
  years = selected_year, 
  specimendata = df2_specimens_allyrs, 
  stationdata = df_stations,
  report_samples = TRUE)

cat("\nDownloaded", nrow(df_snailchem), "records\n")

xtabs(~NAME + STATION_CODE, df_snailchem)

```

### Plot data   
Very boring plot
```{r, fig.width=5, fig.height=2}

library(ggplot2)

df_snailchem %>%
  filter(NAME %in% c("VDSI", "Intersex")) %>%
  ggplot(aes(STATION_CODE, VALUE, color = NAME)) + 
  geom_point()

```




